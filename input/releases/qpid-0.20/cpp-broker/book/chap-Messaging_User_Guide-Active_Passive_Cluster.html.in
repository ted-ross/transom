<div class="docbook"><div class="navheader"><table summary="Navigation header" width="100%"><tr><th align="center" colspan="3">1.13.&#160;Active-passive Messaging Clusters</th></tr><tr><td align="left" width="20%"><a accesskey="p" href="Using-message-groups.html">Prev</a>&#160;</td><th align="center" width="60%">Chapter&#160;1.&#160;
      Running the AMQP Messaging Broker
    </th><td align="right" width="20%">&#160;<a accesskey="n" href="ch01s14.html">Next</a></td></tr></table><hr /></div><div class="section"><div class="titlepage"><div><div><h2 class="title"><a id="chap-Messaging_User_Guide-Active_Passive_Cluster" />1.13.&#160;Active-passive Messaging Clusters</h2></div></div></div><div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="idm247290733152" />1.13.1.&#160;Overview</h3></div></div></div><p>

      The High Availability (HA) module provides
      <em class="firstterm">active-passive</em>, <em class="firstterm">hot-standby</em>
      messaging clusters to provide fault tolerant message delivery.
    </p><p>
      In an active-passive cluster only one broker, known as the
      <em class="firstterm">primary</em>, is active and serving clients at a time. The other
      brokers are standing by as <em class="firstterm">backups</em>. Changes on the primary
      are replicated to all the backups so they are always up-to-date or "hot". Backup
      brokers reject client connection attempts, to enforce the requirement that clients
      only connect to the primary.
    </p><p>
      If the primary fails, one of the backups is promoted to take over as the new
      primary. Clients fail-over to the new primary automatically. If there are multiple
      backups, the other backups also fail-over to become backups of the new primary.
    </p><p>
      This approach relies on an external <em class="firstterm">cluster resource manager</em>
      to detect failures, choose the new primary and handle network partitions. <a class="ulink" href="https://fedorahosted.org/cluster/wiki/RGManager" target="_top">Rgmanager</a> is supported
      initially, but others may be supported in the future.
    </p><div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="idm247287511856" />1.13.1.1.&#160;Avoiding message loss</h4></div></div></div><p>
	In order to avoid message loss, the primary broker <span class="emphasis"><em>delays
	acknowledgment</em></span> of messages received from clients until the message has
	been replicated to and acknowledged by all of the back-up brokers. This means that
	all <span class="emphasis"><em>acknowledged</em></span> messages are safely stored on all the backup
	brokers.
      </p><p>
	Clients keep <span class="emphasis"><em>unacknowledged</em></span> messages in a buffer
	<a class="footnote" href="#ftn.idm247289777552" id="idm247289777552"><sup class="footnote">[1]</sup></a>
	until they are acknowledged by the primary. If the primary fails, clients will
	fail-over to the new primary and <span class="emphasis"><em>re-send</em></span> all their
	unacknowledged messages.
	<a class="footnote" href="#ftn.idm247288628768" id="idm247288628768"><sup class="footnote">[2]</sup></a>
	</p><p>
	  So if the primary crashes, all the <span class="emphasis"><em>acknowledged</em></span> messages will
	  be available on the backup that takes over as the new primary. The
	  <span class="emphasis"><em>unacknowledged</em></span> messages will be re-sent by the clients.  Thus
	  no messages are lost.
	</p><p>
      </p><p>
	Note that this means it is possible for messages to be
	<span class="emphasis"><em>duplicated</em></span>. In the event of a failure it is possible for a
	message to received by the backup that becomes the new primary
	<span class="emphasis"><em>and</em></span> re-sent by the client.  The application must take steps
	to identify and eliminate duplicates.
      </p><p>
	When a new primary is promoted after a fail-over it is initially in
	"recovering" mode. In this mode, it delays acknowledgment of messages
	on behalf of all the backups that were connected to the previous
	primary. This protects those messages against a failure of the new
	primary until the backups have a chance to connect and catch up.
      </p><div class="variablelist"><p class="title"><strong>Status of a HA broker</strong></p><dl class="variablelist"><dt><span class="term">Joining</span></dt><dd><p>
	      Initial status of a new broker that has not yet connected to the primary.
	    </p></dd><dt><span class="term">Catch-up</span></dt><dd><p>
	      A backup broker that is connected to the primary and catching up
	      on queues and messages.
	    </p></dd><dt><span class="term">Ready</span></dt><dd><p>
	      A backup broker that is fully caught-up and ready to take over as
	      primary.
	    </p></dd><dt><span class="term">Recovering</span></dt><dd><p>
	      The newly-promoted primary, waiting for backups to connect and catch up.
	    </p></dd><dt><span class="term">Active</span></dt><dd><p>
	      The active primary broker with all backups connected and caught-up.
	    </p></dd></dl></div></div><div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="idm247288685104" />1.13.1.2.&#160;Replacing the old cluster module</h4></div></div></div><p>
	The High Availability (HA) module replaces the previous
	<em class="firstterm">active-active</em> cluster module.  The new active-passive
	approach has several advantages compared to the existing active-active cluster
	module.
	</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
	    It does not depend directly on openais or corosync. It does not use multicast
	    which simplifies deployment.
	  </li><li class="listitem">
	    It is more portable: in environments that don't support corosync, it can be
	    integrated with a resource manager available in that environment.
	  </li><li class="listitem">
	    It can take advantage of features provided by the resource manager, for example
	    virtual IP addresses.
	  </li><li class="listitem">
	    Improved performance and scalability due to better use of multiple CPUs
	  </li></ul></div><p>
      </p></div><div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="idm247290493248" />1.13.1.3.&#160;Limitations</h4></div></div></div><p>
	There are a number of known limitations in the current preview implementation. These
	will be fixed in the production versions.
      </p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
	  Transactional changes to queue state are not replicated atomically. If the primary crashes
	  during a transaction, it is possible that the backup could contain only part of the
	  changes introduced by a transaction.
	</li><li class="listitem">
	  Configuration changes (creating or deleting queues, exchanges and bindings) are
	  replicated asynchronously. Management tools used to make changes will consider
	  the change complete when it is complete on the primary, it may not yet be
	  replicated to all the backups.
	</li><li class="listitem">
	  Deletions made immediately after a failure (before all the backups are ready)
	  may be lost on a backup. Queues, exchange or bindings that were deleted on the
	  primary could re-appear if that backup is promoted to primary on a subsequent
	  failure.
	</li><li class="listitem">
	  Federated links <span class="emphasis"><em>from</em></span> the primary will be lost in fail over,
	  they will not be re-connected to the new primary. Federation links
	  <span class="emphasis"><em>to</em></span> the primary will fail over.
	</li></ul></div></div></div><div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="idm247288570272" />1.13.2.&#160;Virtual IP Addresses</h3></div></div></div><p>
      Some resource managers (including <span class="command"><strong>rgmanager</strong></span>) support
      <em class="firstterm">virtual IP addresses</em>. A virtual IP address is an IP
      address that can be relocated to any of the nodes in a cluster.  The
      resource manager associates this address with the primary node in the
      cluster, and relocates it to the new primary when there is a failure. This
      simplifies configuration as you can publish a single IP address rather
      than a list.
    </p><p>
      A virtual IP address can be used by clients and backup brokers to connect
      to the primary. The following sections will explain how to configure
      virtual IP addresses for clients or brokers.
    </p></div><div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="idm247286249728" />1.13.3.&#160;Configuring the Brokers</h3></div></div></div><p>
      The broker must load the <code class="filename">ha</code> module, it is loaded by
      default. The following broker options are available for the HA module.
    </p><div class="table"><a id="ha-broker-options" /><p class="title"><strong>Table&#160;1.21.&#160;Broker Options for High Availability Messaging Cluster</strong></p><div class="table-contents"><table border="1" summary="Broker Options for High Availability Messaging Cluster"><colgroup><col align="left" class="c1" /><col align="left" class="c2" /></colgroup><thead><tr><th align="center" colspan="2">
	      Options for High Availability Messaging Cluster
	    </th></tr></thead><tbody><tr><td align="left">
	      <code class="literal">ha-cluster <em class="replaceable"><code>yes|no</code></em></code>
	    </td><td align="left">
	      Set to "yes" to have the broker join a cluster.
	    </td></tr><tr><td align="left">
	      <code class="literal">ha-brokers-url <em class="replaceable"><code>URL</code></em></code>
	    </td><td align="left">
	      <p>
		The URL
		<a class="footnote" href="#ftn.ha-url-grammar" id="ha-url-grammar"><sup class="footnote">[a]</sup></a>
		used by cluster brokers to connect to each other. The URL should
		contain a comma separated list of the broker addresses, rather than a
		virtual IP address. For example:
		<code class="literal">amqp:node1.exaple.com,node2.exaple.com,node3.exaple.com</code>
	      </p>
	    </td></tr><tr><td align="left"><code class="literal">ha-public-url <em class="replaceable"><code>URL</code></em></code> </td><td align="left">
	      <p>
		The URL <a class="footnoteref" href="chap-Messaging_User_Guide-Active_Passive_Cluster.html#ftn.ha-url-grammar"><sup class="footnoteref">[a]</sup></a> used by clients to connect to the cluster.  This can be a list or
		a single virtual IP address. A virtual IP address is recommended as it
		simplifies deployment. If not specified this defaults to the value of
		<code class="literal">ha-brokers-url</code>.
	      </p>
	      <p>
		This option allows you to put client traffic on a different network from
		broker traffic, which is recommended.
	      </p>
	    </td></tr><tr><td align="left"><code class="literal">ha-replicate </code><em class="replaceable"><code>VALUE</code></em></td><td align="left">
	      <p>
		Specifies whether queues and exchanges are replicated by default.
		<em class="replaceable"><code>VALUE</code></em> is one of: <code class="literal">none</code>,
		<code class="literal">configuration</code>, <code class="literal">all</code>.
		For details see <a class="xref" href="chap-Messaging_User_Guide-Active_Passive_Cluster.html#ha-creating-replicated" title="1.13.7.&#160;Creating replicated queues and exchanges">Section&#160;1.13.7, &#8220;Creating replicated queues and exchanges&#8221;</a>.
	      </p>
	    </td></tr><tr><td align="left">
	      <p><code class="literal">ha-username <em class="replaceable"><code>USER</code></em></code></p>
	      <p><code class="literal">ha-password <em class="replaceable"><code>PASS</code></em></code></p>
	      <p><code class="literal">ha-mechanism <em class="replaceable"><code>MECH</code></em></code></p>
	    </td><td align="left">
	      Authentication settings used by HA brokers to connect to each other.
	      If you are using authorization
	      (<a class="xref" href="chap-Messaging_User_Guide-Security.html#sect-Messaging_User_Guide-Security-Authorization" title="1.5.2.&#160;Authorization">Section&#160;1.5.2, &#8220;Authorization&#8221;</a>)
	      then this user must have all permissions.
	    </td></tr><tr><td align="left"><code class="literal">ha-backup-timeout <em class="replaceable"><code>SECONDS</code></em></code> </td><td align="left">
	      <p>
		Maximum time that a recovering primary will wait for an expected
		backup to connect and become ready.
	      </p>
	    </td></tr><tr><td align="left"><code class="literal">link-maintenance-interval <em class="replaceable"><code>SECONDS</code></em></code></td><td align="left">
	      <p>
		Interval for the broker to check link health and re-connect links if need
		be. If you want brokers to fail over quickly you can set this to a
		fraction of a second, for example: 0.1.
	      </p>
	    </td></tr><tr><td align="left"><code class="literal">link-heartbeat-interval <em class="replaceable"><code>SECONDS</code></em></code></td><td align="left">
	      <p>
		Heartbeat interval for replication links. The link will be assumed broken
		if there is no heartbeat for twice the interval.
	      </p>
	    </td></tr></tbody><tbody class="footnotes"><tr><td colspan="2"><div class="footnote" id="ftn.ha-url-grammar"><p><a class="para" href="#ha-url-grammar"><sup class="para">[a] </sup></a>
		  The full format of the URL is given by this grammar:
		  </p><pre class="programlisting">
url = ["amqp:"][ user ["/" password] "@" ] addr ("," addr)*
addr = tcp_addr / rmda_addr / ssl_addr / ...
tcp_addr = ["tcp:"] host [":" port]
rdma_addr = "rdma:" host [":" port]
ssl_addr = "ssl:" host [":" port]'
		  </pre><p>
		  </p></div></td></tr></tbody></table></div></div><br class="table-break" /><p>
      To configure a HA cluster you must set at least <code class="literal">ha-cluster</code> and
      <code class="literal">ha-brokers-url</code>.
    </p></div><div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="idm247290978944" />1.13.4.&#160;The Cluster Resource Manager</h3></div></div></div><p>
      Broker fail-over is managed by a <em class="firstterm">cluster resource
      manager</em>.  An integration with <a class="ulink" href="https://fedorahosted.org/cluster/wiki/RGManager" target="_top">rgmanager</a> is
      provided, but it is possible to integrate with other resource managers.
    </p><p>
      The resource manager is responsible for starting the <span class="command"><strong>qpidd</strong></span> broker
      on each node in the cluster. The resource manager then <em class="firstterm">promotes</em>
      one of the brokers to be the primary. The other brokers connect to the primary as
      backups, using the URL provided in the <code class="literal">ha-brokers-url</code> configuration
      option.
    </p><p>
      Once connected, the backup brokers synchronize their state with the
      primary.  When a backup is synchronized, or "hot", it is ready to take
      over if the primary fails.  Backup brokers continually receive updates
      from the primary in order to stay synchronized.
    </p><p>
      If the primary fails, backup brokers go into fail-over mode. The resource
      manager must detect the failure and promote one of the backups to be the
      new primary.  The other backups connect to the new primary and synchronize
      their state with it.
    </p><p>
      The resource manager is also responsible for protecting the cluster from
      <em class="firstterm">split-brain</em> conditions resulting from a network partition.  A
      network partition divide a cluster into two sub-groups which cannot see each other.
      Usually a <em class="firstterm">quorum</em> voting algorithm is used that disables nodes
      in the inquorate sub-group.
    </p></div><div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="idm247286633376" />1.13.5.&#160;Configuring <span class="command"><strong>rgmanager</strong></span> as resource manager</h3></div></div></div><p>
      This section assumes that you are already familiar with setting up and configuring
      clustered services using <span class="command"><strong>cman</strong></span> and
      <span class="command"><strong>rgmanager</strong></span>. It will show you how to configure an active-passive,
      hot-standby <span class="command"><strong>qpidd</strong></span> HA cluster with <span class="command"><strong>rgmanager</strong></span>.
    </p><p>
      You must provide a <code class="literal">cluster.conf</code> file to configure
      <span class="command"><strong>cman</strong></span> and <span class="command"><strong>rgmanager</strong></span>.  Here is
      an example <code class="literal">cluster.conf</code> file for a cluster of 3 nodes named
      node1, node2 and node3. We will go through the configuration step-by-step.
    </p><pre class="programlisting">
      
&lt;?xml version="1.0"?&gt;
&lt;!--
This is an example of a cluster.conf file to run qpidd HA under rgmanager.
This example assumes a 3 node cluster, with nodes named node1, node2 and node3.

NOTE: fencing is not shown, you must configure fencing appropriately for your cluster.
--&gt;

&lt;cluster name="qpid-test" config_version="18"&gt;
  &lt;!-- The cluster has 3 nodes. Each has a unique nodid and one vote
       for quorum. --&gt;
  &lt;clusternodes&gt;
    &lt;clusternode name="node1.example.com" nodeid="1"/&gt;
    &lt;clusternode name="node2.example.com" nodeid="2"/&gt;
    &lt;clusternode name="node3.example.com" nodeid="3"/&gt;
  &lt;/clusternodes&gt;
  &lt;!-- Resouce Manager configuration. --&gt;
  &lt;rm&gt;
    &lt;!--
	There is a failoverdomain for each node containing just that node.
	This lets us stipulate that the qpidd service should always run on each node.
    --&gt;
    &lt;failoverdomains&gt;
      &lt;failoverdomain name="node1-domain" restricted="1"&gt;
	&lt;failoverdomainnode name="node1.example.com"/&gt;
      &lt;/failoverdomain&gt;
      &lt;failoverdomain name="node2-domain" restricted="1"&gt;
	&lt;failoverdomainnode name="node2.example.com"/&gt;
      &lt;/failoverdomain&gt;
      &lt;failoverdomain name="node3-domain" restricted="1"&gt;
	&lt;failoverdomainnode name="node3.example.com"/&gt;
      &lt;/failoverdomain&gt;
    &lt;/failoverdomains&gt;

    &lt;resources&gt;
      &lt;!-- This script starts a qpidd broker acting as a backup. --&gt;
      &lt;script file="/etc/init.d/qpidd" name="qpidd"/&gt;

      &lt;!-- This script promotes the qpidd broker on this node to primary. --&gt;
      &lt;script file="/etc/init.d/qpidd-primary" name="qpidd-primary"/&gt;

      &lt;!-- This is a virtual IP address for broker replication traffic. --&gt;
      &lt;ip address="20.0.10.200" monitor_link="1"/&gt;

      &lt;!-- This is a virtual IP address on a seprate network for client traffic. --&gt;
      &lt;ip address="20.0.20.200" monitor_link="1"/&gt;
    &lt;/resources&gt;

    &lt;!-- There is a qpidd service on each node, it should be restarted if it fails. --&gt;
    &lt;service name="node1-qpidd-service" domain="node1-domain" recovery="restart"&gt;
      &lt;script ref="qpidd"/&gt;
    &lt;/service&gt;
    &lt;service name="node2-qpidd-service" domain="node2-domain" recovery="restart"&gt;
      &lt;script ref="qpidd"/&gt;
    &lt;/service&gt;
    &lt;service name="node3-qpidd-service" domain="node3-domain"  recovery="restart"&gt;
      &lt;script ref="qpidd"/&gt;
    &lt;/service&gt;

    &lt;!-- There should always be a single qpidd-primary service, it can run on any node. --&gt;
    &lt;service name="qpidd-primary-service" autostart="1" exclusive="0" recovery="relocate"&gt;
      &lt;script ref="qpidd-primary"/&gt;
      &lt;!-- The primary has the IP addresses for brokers and clients to connect. --&gt;
      &lt;ip ref="20.0.10.200"/&gt;
      &lt;ip ref="20.0.20.200"/&gt;
    &lt;/service&gt;
  &lt;/rm&gt;
&lt;/cluster&gt;
      
    </pre><p>
      There is a <code class="literal">failoverdomain</code> for each node containing just that
      one node.  This lets us stipulate that the qpidd service should always run on all
      nodes.
    </p><p>
      The <code class="literal">resources</code> section defines the <span class="command"><strong>qpidd</strong></span>
      script used to start the <span class="command"><strong>qpidd</strong></span> service. It also defines the
      <span class="command"><strong>qpid-primary</strong></span> script which does not
      actually start a new service, rather it promotes the existing
      <span class="command"><strong>qpidd</strong></span> broker to primary status.
    </p><p>
      The <code class="literal">resources</code> section also defines a pair of virtual IP
      addresses on different sub-nets. One will be used for broker-to-broker
      communication, the other for client-to-broker.
    </p><p>
      To take advantage of the virtual IP addresses, <code class="filename">qpidd.conf</code>
      should contain these  lines:
    </p><pre class="programlisting">
      ha-cluster=yes
      ha-brokers-url=20.0.20.200
      ha-public-url=20.0.10.200
    </pre><p>
      This configuration specifies that backup brokers will use 20.0.20.200
      to connect to the primary and will advertise 20.0.10.200 to clients.
      Clients should connect to 20.0.10.200.
    </p><p>
      The <code class="literal">service</code> section defines 3 <code class="literal">qpidd</code>
      services, one for each node. Each service is in a restricted fail-over
      domain containing just that node, and has the <code class="literal">restart</code>
      recovery policy. The effect of this is that rgmanager will run
      <span class="command"><strong>qpidd</strong></span> on each node, restarting if it fails.
    </p><p>
      There is a single <code class="literal">qpidd-primary-service</code> using the
      <span class="command"><strong>qpidd-primary</strong></span> script which is not restricted to a
      domain and has the <code class="literal">relocate</code> recovery policy. This means
      rgmanager will start <span class="command"><strong>qpidd-primary</strong></span> on one of the nodes
      when the cluster starts and will relocate it to another node if the
      original node fails. Running the <code class="literal">qpidd-primary</code> script
      does not start a new broker process, it promotes the existing broker to
      become the primary.
    </p></div><div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="idm247291258848" />1.13.6.&#160;Broker Administration Tools</h3></div></div></div><p>
      Normally, clients are not allowed to connect to a backup broker. However
      management tools are allowed to connect to a backup brokers. If you use
      these tools you <span class="emphasis"><em>must not</em></span> add or remove messages from
      replicated queues, nor create or delete replicated queues or exchanges as
      this will disrupt the replication process and may cause message loss.
    </p><p>
      <span class="command"><strong>qpid-ha</strong></span> allows you to view and change HA configuration settings.
    </p><p>
      The tools <span class="command"><strong>qpid-config</strong></span>, <span class="command"><strong>qpid-route</strong></span> and
      <span class="command"><strong>qpid-stat</strong></span> will connect to a backup if you pass the flag <span class="command"><strong>ha-admin</strong></span> on the
      command line.
    </p></div><div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="ha-creating-replicated" />1.13.7.&#160;Creating replicated queues and exchanges</h3></div></div></div><p>
      By default, queues and exchanges are not replicated automatically. You can change
      the default behavior by setting the <code class="literal">ha-replicate</code> configuration
      option. It has one of the following values:
      </p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><em class="firstterm">all</em>: Replicate everything automatically: queues,
	  exchanges, bindings and messages.
	</li><li class="listitem"><em class="firstterm">configuration</em>: Replicate the existence of queues,
	  exchange and bindings but don't replicate messages.
	</li><li class="listitem"><em class="firstterm">none</em>: Don't replicate anything, this is the default.
	</li></ul></div><p>
    </p><p>
      You can over-ride the default for a particular queue or exchange by passing the
      argument <code class="literal">qpid.replicate</code> when creating the queue or exchange. It
      takes the same values as <code class="literal">ha-replicate</code>
    </p><p>
      Bindings are automatically replicated if the queue and exchange being bound both
      have replication <code class="literal">all</code> or <code class="literal">configuration</code>, they
      are not replicated otherwise.
    </p><p>
      You can create replicated queues and exchanges with the
      <span class="command"><strong>qpid-config</strong></span> management tool like this:
    </p><pre class="programlisting">
      qpid-config add queue myqueue --replicate all
    </pre><p>
      To create replicated queues and exchanges via the client API, add a
      <code class="literal">node</code> entry to the address like this:
    </p><pre class="programlisting">
      "myqueue;{create:always,node:{x-declare:{arguments:{'qpid.replicate':all}}}}"
    </pre><p>
      There are some built-in exchanges created automatically by the broker, these
      exchangs are never replicated. The built-in exchanges are the default (nameless)
      exchange, the AMQP standard exchanges (<code class="literal">amq.direct, amq.topic, amq.fanout</code> and
      <code class="literal">amq.match</code>) and the management exchanges (<code class="literal">qpid.management, qmf.default.direct</code> and
      <code class="literal">qmf.default.topic</code>)
    </p><p>
      Note that if you bind a replicated queue to one of these exchanges, the
      binding wil <span class="emphasis"><em>not</em></span> be replicated, so the queue will not
      have the binding after a fail-over.
    </p></div><div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="idm247286844272" />1.13.8.&#160;Client Connection and Fail-over</h3></div></div></div><p>
      Clients can only connect to the primary broker. Backup brokers
      automatically reject any connection attempt by a client.
    </p><p>
      Clients are configured with the URL for the cluster (details below for
      each type of client). There are two possibilities
      </p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
	  The URL contains multiple addresses, one for each broker in the cluster.
	</li><li class="listitem">
	  The URL contains a single <em class="firstterm">virtual IP address</em>
	  that is assigned to the primary broker by the resource manager.
	  <a class="footnote" href="#ftn.idm247291143472" id="idm247291143472"><sup class="footnote">[3]</sup></a></li></ul></div><p>
      In the first case, clients will repeatedly re-try each address in the URL
      until they successfully connect to the primary. In the second case the
      resource manager will assign the virtual IP address to the primary broker,
      so clients only need to re-try on a single address.
    </p><p>
      When the primary broker fails, clients re-try all known cluster addresses
      until they connect to the new primary.  The client re-sends any messages
      that were previously sent but not acknowledged by the broker at the time
      of the failure.  Similarly messages that have been sent by the broker, but
      not acknowledged by the client, are re-queued.
    </p><p>
      TCP can be slow to detect connection failures. A client can configure a
      connection to use a <em class="firstterm">heartbeat</em> to detect connection
      failure, and can specify a time interval for the heartbeat. If heartbeats
      are in use, failures will be detected no later than twice the heartbeat
      interval. The following sections explain how to enable heartbeat in each
      client.
    </p><p>
      See "Cluster Failover" in <em class="citetitle">Programming in Apache
      Qpid</em> for details on how to keep the client aware of cluster
      membership.
    </p><p>
      Suppose your cluster has 3 nodes: <code class="literal">node1</code>,
      <code class="literal">node2</code> and <code class="literal">node3</code> all using the
      default AMQP port, and you are not using a virtual IP address. To connect
      a client you need to specify the address(es) and set the
      <code class="literal">reconnect</code> property to <code class="literal">true</code>. The
      following sub-sections show how to connect each type of client.
    </p><div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="idm247286205920" />1.13.8.1.&#160;C++ clients</h4></div></div></div><p>
	With the C++ client, you specify multiple cluster addresses in a single URL
	<a class="footnote" href="#ftn.idm247286713200" id="idm247286713200"><sup class="footnote">[4]</sup></a>
	You also need to specify the connection option
	<code class="literal">reconnect</code> to be true.  For example:
      </p><pre class="programlisting">
	qpid::messaging::Connection c("node1,node2,node3","{reconnect:true}");
      </pre><p>
	Heartbeats are disabled by default. You can enable them by specifying a
	heartbeat interval (in seconds) for the connection via the
	<code class="literal">heartbeat</code> option. For example:
	</p><pre class="programlisting">
	  qpid::messaging::Connection c("node1,node2,node3","{reconnect:true,heartbeat:10}");
	</pre><p>
      </p></div><div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="idm247291198832" />1.13.8.2.&#160;Python clients</h4></div></div></div><p>
	With the python client, you specify <code class="literal">reconnect=True</code>
	and a list of <em class="replaceable"><code>host:port</code></em> addresses as
	<code class="literal">reconnect_urls</code> when calling
	<code class="literal">Connection.establish</code> or
	<code class="literal">Connection.open</code>
      </p><pre class="programlisting">
	connection = qpid.messaging.Connection.establish("node1", reconnect=True, reconnect_urls=["node1", "node2", "node3"])
      </pre><p>
	Heartbeats are disabled by default. You can
	enable them by specifying a heartbeat interval (in seconds) for the
	connection via the 'heartbeat' option. For example:
      </p><pre class="programlisting">
	connection = qpid.messaging.Connection.establish("node1", reconnect=True, reconnect_urls=["node1", "node2", "node3"], heartbeat=10)
      </pre></div><div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="idm247287321440" />1.13.8.3.&#160;Java JMS Clients</h4></div></div></div><p>
	In Java JMS clients, client fail-over is handled automatically if it is
	enabled in the connection.  You can configure a connection to use
	fail-over using the <span class="command"><strong>failover</strong></span> property:
      </p><pre class="screen">
	connectionfactory.qpidConnectionfactory = amqp://guest:guest@clientid/test?brokerlist='tcp://localhost:5672'&amp;failover='failover_exchange'
      </pre><p>
	This property can take three values:
      </p><div class="variablelist"><p class="title"><strong>Fail-over Modes</strong></p><dl class="variablelist"><dt><span class="term">failover_exchange</span></dt><dd><p>
	      If the connection fails, fail over to any other broker in the cluster.
	    </p></dd><dt><span class="term">roundrobin</span></dt><dd><p>
	      If the connection fails, fail over to one of the brokers specified in the <span class="command"><strong>brokerlist</strong></span>.
	    </p></dd><dt><span class="term">singlebroker</span></dt><dd><p>
	      Fail-over is not supported; the connection is to a single broker only.
	    </p></dd></dl></div><p>
	In a Connection URL, heartbeat is set using the <span class="command"><strong>idle_timeout</strong></span> property, which is an integer corresponding to the heartbeat period in seconds. For instance, the following line from a JNDI properties file sets the heartbeat time out to 3 seconds:
      </p><pre class="screen">
	connectionfactory.qpidConnectionfactory = amqp://guest:guest@clientid/test?brokerlist='tcp://localhost:5672',idle_timeout=3
      </pre></div></div><div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="idm247289738992" />1.13.9.&#160;Security.</h3></div></div></div><p>
      You can secure your cluster using the authentication and authorization features
      described in <a class="xref" href="chap-Messaging_User_Guide-Security.html" title="1.5.&#160;Security">Section&#160;1.5, &#8220;Security&#8221;</a>.
    </p><p>
      Backup brokers connect to the primary broker and subscribe for management
      events and queue contents. You can specify the identity used to connect
      to the primary with the following options:
    </p><div class="table"><a id="ha-broker-security-options" /><p class="title"><strong>Table&#160;1.22.&#160;Security options for High Availability Messaging Cluster</strong></p><div class="table-contents"><table border="1" summary="Security options for High Availability Messaging Cluster"><colgroup><col align="left" class="c1" /><col align="left" class="c2" /></colgroup><thead><tr><th align="center" colspan="2">
	      Security options for High Availability Messaging Cluster
	    </th></tr></thead><tbody><tr><td align="left">
	      <p><code class="literal">ha-username <em class="replaceable"><code>USER</code></em></code></p>
	      <p><code class="literal">ha-password <em class="replaceable"><code>PASS</code></em></code></p>
	      <p><code class="literal">ha-mechanism <em class="replaceable"><code>MECH</code></em></code></p>
	    </td><td align="left">
	      Authentication settings used by HA brokers to connect to each other.
	      If you are using authorization
	      (<a class="xref" href="chap-Messaging_User_Guide-Security.html#sect-Messaging_User_Guide-Security-Authorization" title="1.5.2.&#160;Authorization">Section&#160;1.5.2, &#8220;Authorization&#8221;</a>)
	      then this user must have all permissions.
	    </td></tr></tbody></table></div></div><br class="table-break" /><p>
      This identity is also used to authorize actions taken on the backup broker to replicate
      from the primary, for example to create queues or exchanges.
    </p></div><div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="idm247287720880" />1.13.10.&#160;Integrating with other Cluster Resource Managers</h3></div></div></div><p>
      To integrate with a different resource manager you must configure it to:
      </p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">Start a qpidd process on each node of the cluster.</li><li class="listitem">Restart qpidd if it crashes.</li><li class="listitem">Promote exactly one of the brokers to primary.</li><li class="listitem">Detect a failure and promote a new primary.</li></ul></div><p>
    </p><p>
      The <span class="command"><strong>qpid-ha</strong></span> command allows you to check if a broker is primary,
      and to promote a backup to primary.
    </p><p>
      To test if a broker is the primary:
      </p><pre class="programlisting">
	qpid-ha -b <em class="replaceable"><code>broker-address</code></em> status --expect=primary
      </pre><p>
      This command will return 0 if the broker at <em class="replaceable"><code>broker-address</code></em>
      is the primary, non-0 otherwise.
    </p><p>
      To promote a broker to primary:
      </p><pre class="programlisting">
	qpid-ha -b <em class="replaceable"><code>broker-address</code></em> promote
      </pre><p>
    </p><p>
      <span class="command"><strong>qpid-ha --help</strong></span> gives information on other commands and options available.
      You can also use <span class="command"><strong>qpid-ha</strong></span> to manually examine and promote brokers. This
      can be useful for testing failover scenarios without having to set up a full resource manager,
      or to simulate a cluster on a single node. For deployment, a resource manager is required.
    </p></div><div class="footnotes"><br /><hr align="left" width="100" /><div class="footnote" id="ftn.idm247289777552"><p><a class="para" href="#idm247289777552"><sup class="para">[1] </sup></a>
	    You can control the maximum number of messages in the buffer by setting the
	    client's <code class="literal">capacity</code>. For details of how to set the capacity
	    in client code see "Using the Qpid Messaging API" in
	    <em class="citetitle">Programming in Apache Qpid</em>.
	  </p></div><div class="footnote" id="ftn.idm247288628768"><p><a class="para" href="#idm247288628768"><sup class="para">[2] </sup></a>
	  Clients must use "at-least-once" reliability to enable re-send of unacknowledged
	  messages. This is the default behavior, no options need be set to enable it. For
	  details of client addressing options see "Using the Qpid Messaging API"
	  in <em class="citetitle">Programming in Apache Qpid</em>.
	  </p></div><div class="footnote" id="ftn.idm247291143472"><p><a class="para" href="#idm247291143472"><sup class="para">[3] </sup></a>Only if the resource manager supports virtual IP addresses</p></div><div class="footnote" id="ftn.idm247286713200"><p><a class="para" href="#idm247286713200"><sup class="para">[4] </sup></a>
	    The full grammar for the URL is:
	  </p><pre class="programlisting">
	    url = ["amqp:"][ user ["/" password] "@" ] addr ("," addr)*
	    addr = tcp_addr / rmda_addr / ssl_addr / ...
	    tcp_addr = ["tcp:"] host [":" port]
	    rdma_addr = "rdma:" host [":" port]
	    ssl_addr = "ssl:" host [":" port]'
	  </pre></div></div></div><div class="navfooter"><hr /><table summary="Navigation footer" width="100%"><tr><td align="left" width="40%"><a accesskey="p" href="Using-message-groups.html">Prev</a>&#160;</td><td align="center" width="20%"><a accesskey="u" href="ch01.html">Up</a></td><td align="right" width="40%">&#160;<a accesskey="n" href="ch01s14.html">Next</a></td></tr><tr><td align="left" valign="top" width="40%">1.12.&#160;
    Using Message Groups
  &#160;</td><td align="center" width="20%"><a accesskey="h" href="index.html">Home</a></td><td align="right" valign="top" width="40%">&#160;1.14.&#160;Queue Replication with the HA module</td></tr></table></div></div>